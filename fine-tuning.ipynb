{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd06ba7-7ff7-46a9-b483-01379fff93a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Guilherme\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# 1. Importar bibliotecas\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df43a5a5-252f-41f2-b013-ff9d40e24aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Carregar dados\n",
    "dataset_path = \"trn.json\"  # Caminho do dataset local\n",
    "dataset = load_dataset(\"json\", data_files=dataset_path, split=\"train\")\n",
    "dataset = dataset.train_test_split(test_size=0.1, seed=42)  # 90% treino, 10% teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf943c6f-ee5d-448d-95dc-bb6f44c8b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Usar modelo pequeno e r√°pido\n",
    "model_name = \"distilgpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token  # Definir token de padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5991b4a-c001-4bff-b725-f48da5270e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Processamento dos dados\n",
    "def process_examples(examples):\n",
    "    texts = [f\"Descreva este produto: {title}\\nDescri√ß√£o: {content}\"\n",
    "             for title, content in zip(examples['title'], examples['content'])]\n",
    "\n",
    "    tokenized = tokenizer(\n",
    "        texts,\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    return tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "135c4e21-3427-4f6b-b625-e111bbf3d367",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2023757/2023757 [04:06<00:00, 8203.71 examples/s]\n",
      "Map: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 224862/224862 [00:24<00:00, 9347.74 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# 5. Processar datasets\n",
    "train_dataset = dataset[\"train\"].map(\n",
    "    process_examples,\n",
    "    batched=True,\n",
    "    remove_columns=['title', 'content']\n",
    ")\n",
    "\n",
    "eval_dataset = dataset[\"test\"].map(\n",
    "    process_examples,\n",
    "    batched=True,\n",
    "    remove_columns=['title', 'content']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49c3dcc1-cbf9-4ee2-8fc0-79eee1a08f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-5): 6 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Carregar e configurar modelo\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# Definir o dispositivo correto (CPU ou ROCm para AMD)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47580321-a532-4f77-8754-ba4e4df3bb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Configurar treinamento\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    fp16=False,  # fp16 s√≥ funciona em GPUs NVIDIA\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",\n",
    "    max_steps=1000\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9077a045-8702-421a-b9b5-c75b84d44dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Criar trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "46badf42-aaa6-432c-a521-18ea0601cf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Iniciando treinamento...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1000' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1000/1000 4:25:09, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2.312500</td>\n",
       "      <td>2.104169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Treinamento conclu√≠do!\n"
     ]
    }
   ],
   "source": [
    "# 9. Executar treinamento\n",
    "print(\"üöÄ Iniciando treinamento...\")\n",
    "trainer.train()\n",
    "print(\"‚úÖ Treinamento conclu√≠do!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2862b26f-703b-41c4-a92d-fc223c0d536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Fun√ß√£o de gera√ß√£o\n",
    "def gerar_descricao(titulo):\n",
    "    prompt = f\"Descreva este produto: {titulo}\\nDescri√ß√£o:\"\n",
    "\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    outputs = model.generate(\n",
    "        inputs.input_ids,\n",
    "        max_new_tokens=100,\n",
    "        temperature=0.5,\n",
    "        do_sample=True, \n",
    "        pad_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True).split(\"Descri√ß√£o:\")[-1].strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b358ca05-f682-4967-ab9b-9aa688de8a43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Exemplo de sa√≠da:\n",
      "Smartphone Android S23 features a built-in Bluetooth connection for the Android 5.0 Marshmallow OS. The device is equipped with a 2.5 inch display and Bluetooth 4.0 support. The device is powered by a 4.5-inch 4.5 inch display with a 1.25 inch (1.25\" x 1.25\") battery. The phone is equipped with a 2.5 inch (1.25\" x 1.25\") battery and a 1\n"
     ]
    }
   ],
   "source": [
    "# 11. Testar\n",
    "print(\"\\nExemplo de sa√≠da:\")\n",
    "descricao = gerar_descricao(\"Smartphone Android S23\")\n",
    "print(descricao) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696052ae-a219-471b-af1e-5f8414a570da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
